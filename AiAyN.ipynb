{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rRKNeepeus1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "in_embed_dim = 100\n",
        "out_embed_dim = 200\n",
        "num_heads = 4\n",
        "num_layers = 3\n",
        "learning_rate = 3e-4\n",
        "max_iters= 10000\n",
        "eval_interval = 1000\n",
        "eval_iters = 100"
      ],
      "metadata": {
        "id": "iyWxPS5K3QAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(19)\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "id": "Eizun8aIQc60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('cmudict-0.7b', 'rb') as f:\n",
        "    data = f.readlines()\n",
        "data = data[126:-5]\n",
        "filtered_data = []\n",
        "for i in range(len(data)):\n",
        "    if i == 35606: continue\n",
        "    filtered_data.append(data[i].decode())\n",
        "with open('cmudict-0.7b.symbols') as f:\n",
        "    symbols = f.read().splitlines()"
      ],
      "metadata": {
        "id": "qoyIkPTy84oI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spellings = []\n",
        "pronounciations = []\n",
        "for d in filtered_data:\n",
        "    split = d.strip(\"\\r\\n\").split()\n",
        "    spellings.append(split[0])\n",
        "    pronounciations.append(['#'] + split[1:] + ['#'])"
      ],
      "metadata": {
        "id": "-RBrALVTDbA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove words with numbers in them\n",
        "for i, s in enumerate(spellings):\n",
        "    if '(' not in s:\n",
        "        if '1' in s or '2' in s or '3' in s or '4' in s or '5' in s or '6' in s or '7' in s or '8' in s or '9' in s or '0' in s:\n",
        "            spellings.pop(i)\n",
        "            pronounciations.pop(i)"
      ],
      "metadata": {
        "id": "0g3L_YcPGj70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't track copies separately\n",
        "for i, s in enumerate(spellings):\n",
        "    spellings[i] = s.strip(\"(1234567890)\")"
      ],
      "metadata": {
        "id": "DKzvaqTTM_x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([len(s) for s in spellings])"
      ],
      "metadata": {
        "id": "SA-thr9aE8vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist([len(p) for p in pronounciations])"
      ],
      "metadata": {
        "id": "W3cS_5DjOijp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_tokens = sorted(list(set(''.join(spellings))))\n",
        "num_tokens = len(in_tokens) + 1\n",
        "in_stoi = {s:i for i, s in enumerate(in_tokens, 1)}\n",
        "in_stoi['#'] = 0\n",
        "in_itos = {i:s for s, i in in_stoi.items()}\n",
        "\n",
        "num_symbols = len(symbols) + 1\n",
        "out_stoi = {s:i for i, s in enumerate(symbols, 1)}\n",
        "out_stoi['#'] = 0\n",
        "out_itos = {i:s for s, i in out_stoi.items()}"
      ],
      "metadata": {
        "id": "1AaS4_Yiauk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 20\n",
        "spellings_padded = []\n",
        "for s in spellings:\n",
        "    if len(s) > MAX_LENGTH:\n",
        "        spellings_padded.append([in_stoi[c] for c in s[:MAX_LENGTH]])\n",
        "    else:\n",
        "        a = [in_stoi[c] for c in s]\n",
        "        for _ in range(MAX_LENGTH - len(a)):\n",
        "            a.append(0)\n",
        "        spellings_padded.append(a)\n",
        "\n",
        "pronounciations_padded = []\n",
        "for p in pronounciations:\n",
        "    if len(p) > MAX_LENGTH + 1:\n",
        "        pronounciations_padded.append([out_stoi[s] for s in p[:MAX_LENGTH+1]])\n",
        "    else:\n",
        "        a = [out_stoi[s] for s in p]\n",
        "        for _ in range(MAX_LENGTH + 1 - len(a)):\n",
        "            a.append(0)\n",
        "        pronounciations_padded.append(a)"
      ],
      "metadata": {
        "id": "vZhHEDe0O8Lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spellings_tensor = torch.tensor(spellings_padded, device=device)\n",
        "pronounciations_tensor = torch.tensor(pronounciations_padded, device=device)\n",
        "# Also maintaining the test set in terms of letters and symbols to cee generation at the end\n",
        "spellings_train, spellings_test, pronounciations_train, pronounciations_test, _, test_words, _, test_pronounce_symbols = train_test_split(spellings_tensor, pronounciations_tensor, spellings, pronounciations, test_size=0.1, random_state=19)\n",
        "spellings_train, spellings_val, pronounciations_train, pronounciations_val = train_test_split(spellings_train, pronounciations_train, test_size=0.15, random_state=19)"
      ],
      "metadata": {
        "id": "4uOE6MkQVxwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(mode='train'):\n",
        "\n",
        "    if mode == 'train':\n",
        "        enc_data = spellings_train\n",
        "        dec_data = pronounciations_train\n",
        "    elif mode == 'val':\n",
        "        enc_data = spellings_val\n",
        "        dec_data = pronounciations_val\n",
        "    elif mode == 'test':\n",
        "        enc_data = spellings_test\n",
        "        dec_data = pronounciations_test\n",
        "    else:\n",
        "        raise ValueError(\"Invalid Mode\")\n",
        "\n",
        "    idxs = torch.randint(enc_data.shape[0], (batch_size,))\n",
        "    x_enc = enc_data[idxs]\n",
        "    x_dec = dec_data[idxs][:, :MAX_LENGTH]\n",
        "    y = dec_data[idxs][:, 1:]\n",
        "\n",
        "    return x_enc, x_dec, y"
      ],
      "metadata": {
        "id": "MRQCCYdQPdDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderHead(nn.Module):\n",
        "\n",
        "    def __init__(self, head_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.q = nn.Linear(in_embed_dim, head_dim, bias=False)\n",
        "        self.k = nn.Linear(in_embed_dim, head_dim, bias=False)\n",
        "        self.v = nn.Linear(in_embed_dim, head_dim, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('X shape:', x.shape)\n",
        "        q = self.q(x)\n",
        "        k = self.k(x)\n",
        "        qkt = q @ k.transpose(-1, -2) / (k.shape[-1]**0.5)\n",
        "        qkt_softmax = F.softmax(qkt, dim=-1)\n",
        "        v = self.v(x)\n",
        "        return qkt_softmax @ v"
      ],
      "metadata": {
        "id": "yKGUnVsI3sD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderHead(nn.Module):\n",
        "\n",
        "    def __init__(self, head_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.q = nn.Linear(out_embed_dim, head_dim, bias=False)\n",
        "        self.k = nn.Linear(out_embed_dim, head_dim, bias=False)\n",
        "        self.v = nn.Linear(out_embed_dim, head_dim, bias=False)\n",
        "        self.register_buffer('mask', torch.tril(torch.ones(MAX_LENGTH, MAX_LENGTH)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        q = self.q(x)\n",
        "        k = self.k(x)\n",
        "        # print('q:', q.shape)\n",
        "        # print('k:', k.shape)\n",
        "        _, time_dim, head_dim = k.shape\n",
        "        # print('head_dim:', head_dim)\n",
        "        # print('kt:', k.transpose(-1, -2).shape)\n",
        "        qkt = q @ k.transpose(-1, -2) / (head_dim**0.5)\n",
        "        # print('qkt:', qkt.shape)\n",
        "        qkt = qkt.masked_fill(self.mask[:time_dim, :time_dim] == 0, float('-inf'))\n",
        "        qkt_softmax = F.softmax(qkt, dim=-1)\n",
        "        v = self.v(x)\n",
        "        return qkt_softmax @ v"
      ],
      "metadata": {
        "id": "FMKV_e-4oIWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttentionHead(nn.Module):\n",
        "\n",
        "    def __init__(self, head_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.q = nn.Linear(out_embed_dim, head_dim, bias=False)\n",
        "        self.k = nn.Linear(in_embed_dim, head_dim, bias=False)\n",
        "        self.v = nn.Linear(in_embed_dim, head_dim, bias=False)\n",
        "\n",
        "    def forward(self, x_enc, x_dec):\n",
        "        q = self.q(x_dec)\n",
        "        k = self.k(x_enc)\n",
        "        qkt = q @ k.transpose(-1, -2) / (k.shape[-1]**0.5)\n",
        "        qkt_softmax = F.softmax(qkt, dim=-1)\n",
        "        v = self.v(x_enc)\n",
        "        return qkt_softmax @ v"
      ],
      "metadata": {
        "id": "C6wNBsbpr1Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHead(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size, is_encoder):\n",
        "        super().__init__()\n",
        "\n",
        "        if is_encoder:\n",
        "            self.heads = nn.ModuleList([EncoderHead(head_size) for _ in range(num_heads)])\n",
        "            self.proj = nn.Linear(head_size * num_heads, in_embed_dim)\n",
        "        else:\n",
        "            self.heads = nn.ModuleList([DecoderHead(head_size) for _ in range(num_heads)])\n",
        "            self.proj = nn.Linear(head_size * num_heads, out_embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"MULTIHEAD\")\n",
        "        # os = []\n",
        "        # for h in self.heads:\n",
        "        #   o = h(x)\n",
        "        #   print(o.shape)\n",
        "        #   os.append(o)\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        return self.proj(out)"
      ],
      "metadata": {
        "id": "Lvdl-mgGtuqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiCrossHead(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.heads = nn.ModuleList([CrossAttentionHead(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, out_embed_dim)\n",
        "\n",
        "    def forward(self, x_enc, x_dec):\n",
        "        out = torch.cat([h(x_enc, x_dec) for h in self.heads], dim=-1)\n",
        "        return self.proj(out)"
      ],
      "metadata": {
        "id": "U7N_L6PI7uYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, embed_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 4 * embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * embed_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "Ss4R16Td2xmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        head_size = in_embed_dim // num_heads\n",
        "\n",
        "        self.mha = MultiHead(num_heads, head_size, True)\n",
        "        self.ln1 = nn.LayerNorm(in_embed_dim)\n",
        "        self.ffnn = FeedForward(in_embed_dim)\n",
        "        self.ln2 = nn.LayerNorm(in_embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        mhout = self.mha(x)\n",
        "        x = self.ln1(x + mhout)\n",
        "        ffout = self.ffnn(x)\n",
        "        return self.ln2(x + ffout)"
      ],
      "metadata": {
        "id": "Vbxxd4674CXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        head_size = out_embed_dim // num_heads\n",
        "\n",
        "        self.mha = MultiHead(num_heads, head_size, False)\n",
        "        self.ln1 = nn.LayerNorm(out_embed_dim)\n",
        "        self.ca = MultiCrossHead(num_heads, head_size)\n",
        "        self.ln2 = nn.LayerNorm(out_embed_dim)\n",
        "        self.ffnn = FeedForward(out_embed_dim)\n",
        "        self.ln3 = nn.LayerNorm(out_embed_dim)\n",
        "\n",
        "    def forward(self, x_enc, x_dec):\n",
        "        mhout = self.mha(x_dec)\n",
        "        x_dec = self.ln1(x_dec + mhout)\n",
        "        caout = self.ca(x_enc, x_dec)\n",
        "        x_dec = self.ln2(x_dec + caout)\n",
        "        ffout = self.ffnn(x_dec)\n",
        "        return self.ln3(x_dec + ffout)"
      ],
      "metadata": {
        "id": "PYTpbp-Y6MaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embedding = nn.Embedding(num_tokens, in_embed_dim)\n",
        "        self.position_embedding = nn.Embedding(MAX_LENGTH, in_embed_dim)\n",
        "        self.blocks = nn.Sequential(*[EncoderBlock() for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        token_embed = self.token_embedding(x)\n",
        "        # print(token_embed.shape)\n",
        "        b = torch.arange(x.shape[1], device=device)\n",
        "        # print(b.shape)\n",
        "        pos_embed = self.position_embedding(b)\n",
        "        x = token_embed + pos_embed\n",
        "        return self.blocks(x)"
      ],
      "metadata": {
        "id": "ENTitQXf-FjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embedding = nn.Embedding(num_symbols, out_embed_dim)\n",
        "        self.position_embedding = nn.Embedding(MAX_LENGTH, out_embed_dim)\n",
        "        # self.blocks = nn.Sequential(*[DecoderBlock() for _ in range(num_layers)])\n",
        "        self.db1 = DecoderBlock()\n",
        "        self.db2 = DecoderBlock()\n",
        "        self.db3 = DecoderBlock()\n",
        "\n",
        "    def forward(self, x_enc, x_dec):\n",
        "        # print(x_dec.shape)\n",
        "        token_embed = self.token_embedding(x_dec)\n",
        "        # print(token_embed.shape)\n",
        "        b = torch.arange(x_dec.shape[1], device=device)\n",
        "        # print(b.shape)\n",
        "        pos_embed = self.position_embedding(b)\n",
        "        x_dec = token_embed + pos_embed\n",
        "        # x_dec = self.token_embedding(x_dec) + self.position_embedding(torch.arange(x_dec.shape[1], device=device))\n",
        "        x_dec = self.db1(x_enc, x_dec)\n",
        "        x_dec = self.db2(x_enc, x_dec)\n",
        "        x_dec = self.db3(x_enc, x_dec)\n",
        "        return x_dec"
      ],
      "metadata": {
        "id": "Cr0zSunWwXFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "        self.head = nn.Linear(out_embed_dim, num_symbols)\n",
        "\n",
        "    def forward(self, spelling, pronounciation, target=None):\n",
        "        x_enc = self.encoder(spelling)\n",
        "        x_dec = self.decoder(x_enc, pronounciation)\n",
        "        logits = self.head(x_dec)\n",
        "\n",
        "        if target==None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            target = target.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, target)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, spelling):\n",
        "        pronounciation = torch.zeros((1, 1), device=device, dtype=torch.int64)\n",
        "        while(True):\n",
        "            logits, loss = self(spelling, pronounciation)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_symb = torch.multinomial(probs, num_samples=1)\n",
        "            pronounciation = torch.cat((pronounciation, next_symb), dim=1)\n",
        "            if next_symb[0] == 0:\n",
        "                return pronounciation\n",
        ""
      ],
      "metadata": {
        "id": "GuNSlnUi0mZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer().to(device)\n",
        "print('Number of Parameters:', sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "id": "IY1QjWX8ZSwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "F88uVKjm242i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "\n",
        "    xb_enc, xb_dec, yb = get_batch('train')\n",
        "\n",
        "    logits, loss = model(xb_enc, xb_dec, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        # losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {loss:.4f}\")"
      ],
      "metadata": {
        "id": "gVewTNAc2wZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.pt')"
      ],
      "metadata": {
        "id": "YL6hHubtttyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.load('model.pt')"
      ],
      "metadata": {
        "id": "LeGu7b73GIbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_loss(mode, model):\n",
        "    if mode == 'train':\n",
        "        enc_data = spellings_train\n",
        "        dec_data = pronounciations_train\n",
        "    elif mode == 'val':\n",
        "        enc_data = spellings_val\n",
        "        dec_data = pronounciations_val\n",
        "    elif mode == 'test':\n",
        "        enc_data = spellings_test\n",
        "        dec_data = pronounciations_test\n",
        "    else:\n",
        "        raise ValueError(\"Invalid Mode\")\n",
        "\n",
        "    x_enc = enc_data\n",
        "    x_dec = dec_data[:, :MAX_LENGTH]\n",
        "    y = dec_data[:, 1:]\n",
        "    _, loss = model(x_enc, x_dec, y)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "q6pMQE8NgIQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_loss('val', model)"
      ],
      "metadata": {
        "id": "5RSeCrnVlSb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_loss('test', model)"
      ],
      "metadata": {
        "id": "h0FupxlUu3y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pronounciation(word):\n",
        "    word = word.upper()\n",
        "    if len(word) > MAX_LENGTH:\n",
        "        word = word[:MAX_LENGTH]\n",
        "    else:\n",
        "        word += '#'*(MAX_LENGTH - len(word))\n",
        "\n",
        "    word_tensor = torch.tensor([in_stoi[c] for c in word], device=device).reshape(1, len(word))\n",
        "    pronounciation = model.generate(word_tensor)\n",
        "    out = [out_itos[i.item()] for i in list(pronounciation[0])]\n",
        "    return ' '.join(out[1:-1])"
      ],
      "metadata": {
        "id": "1UobkavLRTYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dets(word, pro, pred_pro):\n",
        "    return f\"| {word} | {pro} | {pred_pro} |\""
      ],
      "metadata": {
        "id": "f3JpHonVjrws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    word = test_words[i]\n",
        "    pro = ' '.join(test_pronounce_symbols[i][1:-1])\n",
        "    pred_pro = get_pronounciation(word)\n",
        "    print(dets(word, pro, pred_pro))"
      ],
      "metadata": {
        "id": "d1Wy6aPRVKuG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}